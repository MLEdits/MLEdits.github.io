<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        emb = self.word_lut(input)
        if self.positional_encoding:
            emb = emb + Variable(self.pe[:emb.size(0), :1, :emb.size(2)].expand_as(emb))
            emb = emb * math.sqrt(<a id="change">emb.size(2)</a>)
            
        &#47&#47 n.b. you can increase performance if you compute W_ih * x for all
        &#47&#47 iterations in parallel, but that&quots only possible if</code></pre><h3>After Change</h3><pre><code class='java'>
            hidden_t (FloatTensor): Last hidden state tuple (1 x batch x rnn_size)
            attns (FloatTensor): Dictionary of (src_len x batch)
        
        <a id="change">if False:
            if self.decoder_layer == "transformer" and hidden:
                input = torch.cat([hidden, input], 0)
            
       </a> emb = self.word_lut(input)
        if self.positional_encoding:
            emb = emb + Variable(self.pe[:emb.size(0), :1, :emb.size(2)].expand_as(emb))
            &#47&#47 emb = emb * math.sqrt(emb.size(2))</code></pre>