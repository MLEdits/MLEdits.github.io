<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 TODO: Doesn&quott make much sense over training data, averaging with initial
    &#47&#47 (bad) predictions.
    auc, update_auc_op = tf.metrics.auc(labels, logits, curve=&quotPR&quot)
    <a id="change">tf.add_to_collection(&quotmetric_ops&quot, update_auc_op)</a>
    tf.add_to_collection(&quotmetrics&quot, auc)
    tf.summary.scalar(&quotauc&quot, auc)

</code></pre><h3>After Change</h3><pre><code class='java'>
    normalized_logits = tf.sigmoid(logits)

    &#47&#47 Add one AUC metric per class, so we can see individual performance too.
    for cls in range(<a id="change">logits.shape[1]</a>):
        auc, _ = tf.metrics.auc(
            labels[:, cls], normalized_logits[:, cls],
            curve=&quotPR&quot, name=f&quotiauc/{cls}&quot,</code></pre>