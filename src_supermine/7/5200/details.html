<html><h3>532096f9f9a96f689ee644cdb3560def98a4c410,auto_ml/predictor.py,Predictor,_get_xgb_feat_importances,#Predictor#Any#,279
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        print(fscore)

        fscore_list = [[int(k[1:]), v] for k, v in fscore.viewitems()]
        <a id="change">print(&quotfscore_list&quot)</a>
        print(fscore_list)
        sorted_fscore = fscore_list.sort(key=lambda x: x[0])
        print(&quotfscore_list after sorting&quot)
        print(fscore_list)</code></pre><h3>After Change</h3><pre><code class='java'>


        feature_infos = []
        <a id="change">sum_of_all_feature_importances = 0.0</a>

        <a id="change">for idx_and_result in fscore_list:
            idx = idx_and_result[0]
            &#47&#47 Use the index that we grabbed above to find the human-readable feature name
            feature_name = trained_feature_names[idx]
            feat_importance = idx_and_result[1]

            &#47&#47 If we sum up all the feature importances and then divide by that sum, we will be able to have each feature importance as it&quots relative feature imoprtance, and the sum of all of them will sum up to 1, just as it is in scikit-learn.
            sum_of_all_feature_importances += feat_importance
            feature_infos.append([feature_name, feat_importance])

       </a> sorted_feature_infos = sorted(feature_infos, key=lambda x: x[1])

        print(&quotHere are the feature_importances from the tree-based model:&quot)
        print(&quotThe printed list will only contain at most the top 50 features.&quot)</code></pre><img src="21900556.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ClimbsRocks/auto_ml/commit/532096f9f9a96f689ee644cdb3560def98a4c410#diff-893454c3b7604c9e39cf39dfbdd6f1f0b1c6707e4fec48a68ceec16035875121L286' target='_blank'>Link</a></div><div id='project'> Project Name: ClimbsRocks/auto_ml</div><div id='commit'> Commit Name: 532096f9f9a96f689ee644cdb3560def98a4c410</div><div id='time'> Time: 2016-08-20</div><div id='author'> Author: ClimbsBytes@gmail.com</div><div id='file'> File Name: auto_ml/predictor.py</div><div id='class'> Class Name: Predictor</div><div id='method'> Method Name: _get_xgb_feat_importances</div><BR><BR><div id='link'><a href='https://github.com/AlexEMG/DeepLabCut/commit/199f387b50df1f32ded6ac5d54b68f08f009661b#diff-20dbc20740109196950c50bc0d33f6e24b58b75d5c91ed634e505c235f237c12L77' target='_blank'>Link</a></div><div id='project'> Project Name: AlexEMG/DeepLabCut</div><div id='commit'> Commit Name: 199f387b50df1f32ded6ac5d54b68f08f009661b</div><div id='time'> Time: 2019-09-19</div><div id='author'> Author: amathis@fas.harvard.edu</div><div id='file'> File Name: deeplabcut/create_project/new.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: create_new_project</div><BR><BR><div id='link'><a href='https://github.com/NifTK/NiftyNet/commit/c8b28432a637a780eed96547260722ff3dede57e#diff-c80cf3e5e643430c5cd08bb5be53934019e8c051fad8ae50eb493f714cf8b495L350' target='_blank'>Link</a></div><div id='project'> Project Name: NifTK/NiftyNet</div><div id='commit'> Commit Name: c8b28432a637a780eed96547260722ff3dede57e</div><div id='time'> Time: 2017-10-04</div><div id='author'> Author: wenqi.li@ucl.ac.uk</div><div id='file'> File Name: niftynet/engine/sampler_selective.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: rand_choice_coordinates</div><BR>