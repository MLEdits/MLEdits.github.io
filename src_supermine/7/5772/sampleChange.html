<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
@pytest.mark.skipif(torch.cuda.device_count() &lt; 2, reason="test requires multi-GPU machine")
def test_dp_resume(tmpdir):
    Make sure DP continues training correctly.
    <a id="change">hparams = EvalModelTemplate.get_default_hparams()</a>
    model = <a id="change">EvalModelTemplate(**hparams)</a>

    trainer_options = dict(max_epochs=1, gpus=2, accelerator=&quotdp&quot, default_root_dir=tmpdir)

    &#47&#47 get logger
    logger = tutils.get_default_logger(tmpdir)

    &#47&#47 exp file to get weights
    &#47&#47 logger file to get weights
    checkpoint = tutils.init_checkpoint_callback(logger)

    &#47&#47 add these to the trainer options
    trainer_options[&quotlogger&quot] = logger
    trainer_options[&quotcheckpoint_callback&quot] = checkpoint

    &#47&#47 fit model
    trainer = Trainer(**trainer_options)
    trainer.is_slurm_managing_tasks = True
    trainer.fit(model)

    &#47&#47 track epoch before saving. Increment since we finished the current epoch, don&quott want to rerun
    real_global_epoch = trainer.current_epoch + 1

    &#47&#47 correct result and ok accuracy
    assert trainer.state == TrainerState.FINISHED, f"Training failed with {trainer.state}"

    &#47&#47 ---------------------------
    &#47&#47 HPC LOAD/SAVE
    &#47&#47 ---------------------------
    &#47&#47 save
    trainer.checkpoint_connector.hpc_save(tmpdir, logger)

    &#47&#47 init new trainer
    new_logger = tutils.get_default_logger(tmpdir, version=logger.version)
    trainer_options[&quotlogger&quot] = new_logger
    trainer_options[&quotcheckpoint_callback&quot] = ModelCheckpoint(dirpath=tmpdir)
    trainer_options[&quotlimit_train_batches&quot] = 0.5
    trainer_options[&quotlimit_val_batches&quot] = 0.2
    trainer_options[&quotmax_epochs&quot] = 1
    new_trainer = Trainer(**trainer_options)

    &#47&#47 set the epoch start hook so we can predict before the model does the full training
    def assert_good_acc():
        assert new_trainer.current_epoch == real_global_epoch and new_trainer.current_epoch &gt; 0

        &#47&#47 if model and state loaded correctly, predictions will be good even though we
        &#47&#47 haven&quott trained with the new loaded model
        dp_model = new_trainer.model
        dp_model.eval()
        dp_model.module.module.running_stage = RunningStage.EVALUATING

        dataloader = trainer.train_dataloader
        tpipes.run_prediction(dp_model, dataloader, dp=True)

    &#47&#47 new model
    model = <a id="change">EvalModelTemplate(**hparams)</a>
    model.on_train_start = assert_good_acc

    &#47&#47 fit new model which should load hpc weights
    new_trainer.fit(model)</code></pre><h3>After Change</h3><pre><code class='java'>
@pytest.mark.skipif(torch.cuda.device_count() &lt; 2, reason="test requires multi-GPU machine")
def test_dp_resume(tmpdir):
    Make sure DP continues training correctly.
    model = <a id="change">BoringModel()</a>

    trainer_options = dict(max_epochs=1, gpus=2, accelerator=&quotdp&quot, default_root_dir=tmpdir)

    &#47&#47 get logger</code></pre>