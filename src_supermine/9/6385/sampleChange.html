<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    :return: the loss (cross_entropy + Dice)

    
    <a id="change">if weight_map is not None:
        raise NotImplementedError

   </a> prediction = tf.cast(prediction, tf.float32)
    loss_xent = cross_entropy(prediction, ground_truth)

    softmax_of_logits = tf.nn.softmax(prediction, axis=-1)

    &#47&#47 Dice as according to the paper:
    num_classes = tf.shape(prediction)[-1]
    <a id="change">one_hot = labels_to_one_hot(ground_truth, num_classes=num_classes)</a>

    dice_numerator = 2.0 * tf.sparse_reduce_sum(one_hot * softmax_of_logits,
                                                reduction_axes=[0])
    dice_denominator = tf.reduce_sum(softmax_of_logits, reduction_indices=[0]) + \</code></pre><h3>After Change</h3><pre><code class='java'>
    loss_xent = cross_entropy(prediction, ground_truth, weight_map=weight_map)

    &#47&#47 Dice as according to the paper:
    <a id="change">one_hot = labels_to_one_hot(ground_truth, num_classes=num_classes)</a>
    softmax_of_logits = tf.nn.softmax(prediction)

    if weight_map is not None:
        <a id="change">weight_map_nclasses = tf.tile(tf.expand_dims(tf.reshape(weight_map, [-1]), 1), [1, num_classes])</a>
        <a id="change">dice_numerator = 2.0 * tf.sparse_reduce_sum(weight_map_nclasses * one_hot * softmax_of_logits,
                                                    reduction_axes=[0])</a>
        dice_denominator = tf.reduce_sum(weight_map_nclasses * softmax_of_logits,
                                         reduction_indices=[0]) + \
                           tf.sparse_reduce_sum(one_hot * weight_map_nclasses, reduction_axes=[0])
</code></pre>