<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        gradients = self.actor_network.sess.run(actor_online_network.weighted_gradients,
                                                feed_dict={
                                                    actor_online_network.gradients_weights_ph: -action_gradients,
                                                    <a id="change">actor_online_network.inputs[0]</a>: current_states
                                                })
        if self.actor_network.has_global:
            self.actor_network.global_network.apply_gradients(gradients)</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 TD error = r + discount*max(q_st_plus_1) - q_st
        next_actions = self.actor_network.target_network.predict(next_states)
        <a id="change">inputs = copy.copy(next_states)</a>
        <a id="change">inputs[&quotaction&quot]</a> = next_actions
        q_st_plus_1 = self.critic_network.target_network.predict(inputs)
        TD_targets = np.expand_dims(rewards, -1) + \
                     (1.0 - np.expand_dims(game_overs, -1)) * self.tp.agent.discount * q_st_plus_1</code></pre>