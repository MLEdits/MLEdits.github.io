<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                     target_output_sample,
                     target,
                     audio_length,
                     <a id="change">self.params["logdir"]</a>, step,
                     append="train", 
                     save_to_tensorboard = self.save_to_tensorboard)
    dict_to_log[&quotimage&quot] = im_summary

    predicted_final_spectrogram_sample = predicted_final_spectrogram_sample[:audio_length-1,:]
    <a id="change">if "magnitude" in self.get_data_layer().params[&quotoutput_type&quot]:
      predicted_final_spectrogram_sample = self.get_data_layer().denormalize(predicted_final_spectrogram_sample)
      predicted_final_spectrogram_sample = np.exp(predicted_final_spectrogram_sample)
      wav_summary = save_audio(predicted_final_spectrogram_sample, self.params["logdir"], step,
        save_to_tensorboard = self.save_to_tensorboard)
      dict_to_log[&quotaudio&quot] = wav_summary
    elif "mel" in self.get_data_layer().params[&quotoutput_type&quot]:
      predicted_final_spectrogram_sample = self.get_data_layer().inverse_mel(predicted_final_spectrogram_sample)
      wav_summary = save_audio(predicted_final_spectrogram_sample, self.params["logdir"], step,
        save_to_tensorboard = self.save_to_tensorboard)
      dict_to_log[&quotaudio&quot] = wav_summary
    
   </a> if self.save_to_tensorboard:
      return dict_to_log
    else:
      return {}</code></pre><h3>After Change</h3><pre><code class='java'>
    target_output_sample = target_output[0]
    audio_length = output_values[4][0]

    predicted_final_spectrogram_sample = <a id="change">self</a>.get_data_layer().get_magnitude_spec(y_sample)
    im_summary = plot_spectrogram_w_target(y_sample, y_sample,
                     predicted_final_spectrogram_sample,
                     attention_mask_sample,</code></pre>