<html><h3>35b2c4917344f338eda67c78673cf4064b3b4265,examples/reinforcement_learning/tutorial_C51.py,DQN,train,#DQN#Any#Any#Any#Any#Any#,234
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        self._train_func(b_o, b_index, b_m)

        <a id="change">self.niter</a> += 1
        if self.niter % target_q_update_freq == 0:
            sync(self.qnet, self.targetqnet)
            <a id="change">path = os.path.join(args.save_path, &quot{}.npz&quot.format(self.niter))</a>
            <a id="change">tl.files.save_npz(self.qnet.trainable_weights, name=path)</a>

    @tf.function
    def _train_func(self, b_o, b_index, b_m):
        with tf.GradientTape() as tape:</code></pre><h3>After Change</h3><pre><code class='java'>
    def _qvalues_func(self, obv):
        return self.qnet(obv)

    def train(<a id="change">self</a>, b_o, b_a, b_r, b_o_, b_d):
        &#47&#47 TODO: move q_estimation in tf.function
        b_dist_ = np.exp(self.targetqnet(b_o_).numpy())
        b_a_ = (b_dist_ * vrange).sum(-1).argmax(1)
        b_tzj = np.clip(reward_gamma * (1 - b_d[:, None]) * vrange[None, :] + b_r[:, None], min_value, max_value)
        b_i = (b_tzj - min_value) / deltaz
        b_l = np.floor(b_i).astype(&quotint64&quot)
        b_u = np.ceil(b_i).astype(&quotint64&quot)
        templ = b_dist_[range(batch_size), b_a_, :] * (b_u - b_i)
        tempu = b_dist_[range(batch_size), b_a_, :] * (b_i - b_l)
        b_m = np.zeros((batch_size, atom_num))
        &#47&#47 TODO: aggregate value by index and batch update (scatter_add)
        for j in range(batch_size):
            for k in range(atom_num):
                b_m[j][b_l[j][k]] += templ[j][k]
                b_m[j][b_u[j][k]] += tempu[j][k]
        b_m = tf.convert_to_tensor(b_m, dtype=&quotfloat32&quot)
        b_index = np.stack([range(batch_size), b_a], 1)
        b_index = tf.convert_to_tensor(b_index, &quotint64&quot)

        self._train_func(b_o, b_index, b_m)

        self.niter += 1
        if self.niter % target_q_update_freq == 0:
            sync(self.qnet, self.targetqnet)
            <a id="change">self.save(args.save_path)</a>

    def save(self, path):
        if path is None:</code></pre><img src="37367502.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 15</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorlayer/tensorlayer/commit/35b2c4917344f338eda67c78673cf4064b3b4265#diff-2fdc0b632561ea4b43293529c553ed0fd3ebd82f6d80d15dcb13ee19f9028b04L226' target='_blank'>Link</a></div><div id='project'> Project Name: tensorlayer/tensorlayer</div><div id='commit'> Commit Name: 35b2c4917344f338eda67c78673cf4064b3b4265</div><div id='time'> Time: 2020-02-07</div><div id='author'> Author: 34995488+Tokarev-TT-33@users.noreply.github.com</div><div id='file'> File Name: examples/reinforcement_learning/tutorial_C51.py</div><div id='class'> Class Name: DQN</div><div id='method'> Method Name: train</div><BR><BR><div id='link'><a href='https://github.com/tensorlayer/tensorlayer/commit/35b2c4917344f338eda67c78673cf4064b3b4265#diff-1c701d26a297c0ef75af29621b84d16b2415fafdaecc78c73607f3fdaeb81375L327' target='_blank'>Link</a></div><div id='project'> Project Name: tensorlayer/tensorlayer</div><div id='commit'> Commit Name: 35b2c4917344f338eda67c78673cf4064b3b4265</div><div id='time'> Time: 2020-02-07</div><div id='author'> Author: 34995488+Tokarev-TT-33@users.noreply.github.com</div><div id='file'> File Name: examples/reinforcement_learning/tutorial_DQN_variants.py</div><div id='class'> Class Name: DQN</div><div id='method'> Method Name: train</div><BR><BR><div id='link'><a href='https://github.com/tensorlayer/tensorlayer/commit/bb857bb2469689da4d2e19473049e47ccc1be04a#diff-0a822207a4ca5fd1b0144ec09a353c6a56538adbd8ad01b2e5fe178571fe413bL432' target='_blank'>Link</a></div><div id='project'> Project Name: tensorlayer/tensorlayer</div><div id='commit'> Commit Name: bb857bb2469689da4d2e19473049e47ccc1be04a</div><div id='time'> Time: 2020-02-07</div><div id='author'> Author: 34995488+Tokarev-TT-33@users.noreply.github.com</div><div id='file'> File Name: examples/reinforcement_learning/tutorial_prioritized_replay.py</div><div id='class'> Class Name: DQN</div><div id='method'> Method Name: train</div><BR>