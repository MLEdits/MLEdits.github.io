<html><h3>5972cb1690cafd70c2d1ef36c42707ec36e05276,onmt/Models.py,Decoder,forward,#Decoder#Any#Any#Any#Any#Any#,288
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        emb = self.word_lut(input)
        if self.positional_encoding:
            emb = emb + Variable(self.pe[<a id="change">:emb.size(0), :1, :</a>emb.size(2)]
                                 .expand_as(emb))

        &#47&#47 n.b. you can increase performance if you compute W_ih * x for all
        &#47&#47 iterations in parallel, but that&quots only possible if
        &#47&#47 self.input_feed=False
        outputs = []

        &#47&#47 Setup the different types of attention.
        attns = {"std": []}
        if self._copy:
            attns["copy"] = []
        if self._coverage:
            attns["coverage"] = []

        output = init_feed
        coverage = None

        if self.decoder_layer == "transformer":
            <a id="change">output = self.emb_dropout(emb.transpose(0, 1).contiguous())</a>
            src_context = context.transpose(0, 1).contiguous()
            for i in range(self.layers):
                output, attn = self.transformer[i](output, src_context,
                                                   src[:, :, 0], input)</code></pre><h3>After Change</h3><pre><code class='java'>
        if has_transformer_hidden:
            input = torch.cat([hidden[0].squeeze(2), input], 0)

        emb = self.embeddings(<a id="change">input.unsqueeze(2)</a>)

        &#47&#47 n.b. you can increase performance if you compute W_ih * x for all
        &#47&#47 iterations in parallel, but that&quots only possible if</code></pre><img src="2243746.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/OpenNMT/OpenNMT-py/commit/5972cb1690cafd70c2d1ef36c42707ec36e05276#diff-fa3c76576694291de650c11f3e3a4d00a68e887bfedddaf1079b5a7ac6903d6cL244' target='_blank'>Link</a></div><div id='project'> Project Name: OpenNMT/OpenNMT-py</div><div id='commit'> Commit Name: 5972cb1690cafd70c2d1ef36c42707ec36e05276</div><div id='time'> Time: 2017-07-04</div><div id='author'> Author: sasha.rush@gmail.com</div><div id='file'> File Name: onmt/Models.py</div><div id='class'> Class Name: Decoder</div><div id='method'> Method Name: forward</div><BR><BR><div id='link'><a href='https://github.com/OpenNMT/OpenNMT-py/commit/668c3ef362995c55633fde592354160fec1d1efd#diff-7e1f0d71487d71c099bab18ff27c8711076ea42513b92fc8e79a152477bd5811L114' target='_blank'>Link</a></div><div id='project'> Project Name: OpenNMT/OpenNMT-py</div><div id='commit'> Commit Name: 668c3ef362995c55633fde592354160fec1d1efd</div><div id='time'> Time: 2019-06-27</div><div id='author'> Author: dylan.flaute@gmail.com</div><div id='file'> File Name: onmt/encoders/transformer.py</div><div id='class'> Class Name: TransformerEncoder</div><div id='method'> Method Name: forward</div><BR><BR><div id='link'><a href='https://github.com/OpenNMT/OpenNMT-py/commit/668c3ef362995c55633fde592354160fec1d1efd#diff-092c23e5f0c96b0c1263d554e5d417f5238ec0e7d02cda8f5587d0aebc3a543fL194' target='_blank'>Link</a></div><div id='project'> Project Name: OpenNMT/OpenNMT-py</div><div id='commit'> Commit Name: 668c3ef362995c55633fde592354160fec1d1efd</div><div id='time'> Time: 2019-06-27</div><div id='author'> Author: dylan.flaute@gmail.com</div><div id='file'> File Name: onmt/decoders/transformer.py</div><div id='class'> Class Name: TransformerDecoder</div><div id='method'> Method Name: forward</div><BR>