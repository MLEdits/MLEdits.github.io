<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    if code == 0:
        output = output.decode(&quotutf-8&quot)
        return warn_return(len(output.strip().split(&quot\n&quot)), "Found nvidia-smi. ")
    <a id="change">try:
        &#47&#47 Use NVML to query device properties
        with NVMLContext() as ctx:
            return warn_return(ctx.num_devices(), "NVML found nvidia devices. ")
    except Exception:
        &#47&#47 Fallback
        logger.info("Loading local devices by TensorFlow ...")

        try:
            import tensorflow as tf
            &#47&#47 available since TF 1.14
            gpu_devices = tf.config.experimental.list_physical_devices(&quotGPU&quot)
        except AttributeError:
            from tensorflow.python.client import device_lib
            local_device_protos = device_lib.list_local_devices()
            &#47&#47 Note this will initialize all GPUs and therefore has side effect
            &#47&#47 https://github.com/tensorflow/tensorflow/issues/8136
            gpu_devices = [x.name for x in local_device_protos if x.device_type == &quotGPU&quot]
        return len(gpu_devices)


</a>get_nr_gpu = get_num_gpu
</code></pre><h3>After Change</h3><pre><code class='java'>
    env = os.environ.get(&quotCUDA_VISIBLE_DEVICES&quot, None)
    if env:
        num_dev = len(env.split(&quot,&quot))
        <a id="change">assert num_dev &lt;= nvml_num_dev, \
            "Only {} GPU(s) available, but CUDA_VISIBLE_DEVICES is set to {}".format(nvml_num_dev, env)</a>
        return warn_return(num_dev, "Found non-empty CUDA_VISIBLE_DEVICES. ")

    output, code = subproc_call("nvidia-smi -L", timeout=5)
    if code == 0:</code></pre>