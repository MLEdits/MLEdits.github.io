<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    self._initialize(parameters)
    for update, parameter, momentum in zip(updates, parameters,
                                           self.accumulated_momentum):
      <a id="change">if update is not None:
        optimizer_utils.check_same_dtype(update, parameter)
        lr = tf.cast(self.learning_rate, update.dtype)
        mu = tf.cast(self.momentum, update.dtype)
        if isinstance(update, tf.IndexedSlices):
          update, indices = optimizer_utils.deduplicate_indexed_slices(
              update.values, update.indices)
          sparse_momentum_update = (mu * momentum.sparse_read(indices)) + update
          momentum.scatter_update(
              tf.IndexedSlices(sparse_momentum_update, indices))
          if self.use_nesterov:
            parameter.scatter_sub(
                tf.IndexedSlices(
                    (lr * update) + (lr * mu * sparse_momentum_update),
                    indices))
          else:
            parameter.scatter_sub(
                tf.IndexedSlices(lr * sparse_momentum_update, indices))
        else:
          momentum.assign((mu * momentum) + update)
          if self.use_nesterov:
            parameter.assign_sub((lr * update) + (lr * mu * momentum))
          else:
            parameter.assign_sub(lr * momentum)


</a>class FastMomentum(base.Optimizer):
  SGD with Momentum module.

  def __init__(self,</code></pre><h3>After Change</h3><pre><code class='java'>
    self._initialize(parameters)
    for update, param, momentum_var in zip(updates, parameters,
                                           self.accumulated_momentum):
      <a id="change">if update is None:
        continue

     </a> optimizer_utils.check_same_dtype(update, param)
      learning_rate = tf.cast(self.learning_rate, update.dtype)
      mu = tf.cast(self.momentum, update.dtype)

      if isinstance(update, tf.IndexedSlices):
        &#47&#47 Sparse read our state.
        update, indices = optimizer_utils.deduplicate_indexed_slices(update)
        momentum = momentum_var.sparse_read(indices)

        &#47&#47 Compute and apply a sparse update to our parameter and state.
        update, momentum = momentum_update(update, learning_rate, mu, momentum,
                                           self.use_nesterov)
        momentum_var.scatter_update(tf.IndexedSlices(momentum, indices))
        param.scatter_sub(tf.IndexedSlices(update, indices))

      else:
        &#47&#47 Compute and apply a dense update.
        <a id="change">update, momentum = momentum_update(update, learning_rate, mu,
                                           momentum_var, self.use_nesterov)</a>
        <a id="change">momentum_var.assign(momentum)</a>
        param.assign_sub(update)


class FastMomentum(base.Optimizer):</code></pre>