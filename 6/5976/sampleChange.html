<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        "&#47&#47&#47&#47ing", ","
    ]
    with tempfile.NamedTemporaryFile(delete=False) as vocab_writer:
        vocab_writer.write(<a id="change">""</a>.join(
            [x + "\n" <a id="change">for</a> x in vocab_tokens]).encode("utf-8"))

    vocab_file = vocab_writer.name
</code></pre><h3>After Change</h3><pre><code class='java'>
    golden_tokens = [&quotfurther&quot, &quot&#47&#47&#47&#47more&quot, &quot,&quot, &quotunder&quot, &quotthe&quot, &quotmicro&quot, &quot&#47&#47&#47&#47scope&quot, &quotneither&quot, &quotentity&quot, &quotcontains&quot,
                     &quot[UNK]&quot, &quotglands&quot, &quot.&quot, &quot此&quot, &quot外&quot, &quot,&quot, &quot在&quot, &quot显&quot, &quot微&quot, &quot镜&quot, &quot下&quot]

    <a id="change">vocab_dict = {}</a>
    for idx, token in enumerate(vocab_tokens):
        <a id="change">vocab_dict[token]</a> = idx

    clean_unit = units.BertClean()
    cleaned_text = clean_unit.transform(raw_text)
    chinese_tokenize_unit = units.ChineseTokenize()
    chinese_tokenized_text = chinese_tokenize_unit.transform(cleaned_text)
    basic_tokenize_unit = units.BasicTokenize()
    basic_tokens = basic_tokenize_unit.transform(chinese_tokenized_text)
    <a id="change">wordpiece_unit = units.WordPieceTokenize(vocab_dict)</a>
    wordpiece_tokens = wordpiece_unit.transform(basic_tokens)

    assert wordpiece_tokens == golden_tokens
</code></pre>