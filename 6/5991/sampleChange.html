<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    if tf_be and &quotmkl&quot == tf_be.lower():
        if py3_ver == 5 or py3_ver == 6:
            tf_mkl_url_real = tf_mkl_url.format(tf_version, py3_ver, py3_ver)
            <a id="change">subprocess.run(&quotpip3 install -U {}&quot.format(tf_mkl_url_real), shell=True)</a>
    elif tf_be and &quotgpu&quot == tf_be.lower() and gpu_available:
        chosen_tf = &quottensorflow-gpu=={}&quot.format(tf_version)
requirements.append(chosen_tf)
</code></pre><h3>After Change</h3><pre><code class='java'>


&#47&#47 required packages for NLP Architect
<a id="change">with open(&quotrequirements.txt&quot) as fp:
    install_requirements = fp.readlines()

&#47&#47 requirements = [
&#47&#47     &#47&#47 DL frameworks
&#47&#47     "dynet==2.0.2",
&#47&#47     &#47&#47 NLP/DS apps
&#47&#47     "spacy==2.0.18",
&#47&#47     "nltk",
&#47&#47     "gensim",
&#47&#47     "sklearn",
&#47&#47     "scipy",
&#47&#47     "numpy&lt;=1.14.5",
&#47&#47     "tensorflow_hub",
&#47&#47     "elasticsearch",
&#47&#47     "fasttextmirror",  &#47&#47 temp fix
&#47&#47     &#47&#47 "msgpack==0.5.6",  &#47&#47 temp fix
&#47&#47     &#47&#47 General utils
&#47&#47     "newspaper3k",
&#47&#47     "wordfreq",
&#47&#47     "seqeval",
&#47&#47     "pywikibot",
&#47&#47     "num2words",
&#47&#47     "hyperopt",
&#47&#47     "h5py",
&#47&#47     "pandas",
&#47&#47     "tqdm",
&#47&#47     "ftfy",
&#47&#47     "bokeh",
&#47&#47     "six",
&#47&#47     "future",
&#47&#47     "requests",
&#47&#47     "termcolor",
&#47&#47     "pillow",
&#47&#47     "setuptools",
&#47&#47     &#47&#47 Server
&#47&#47     "hug",
&#47&#47     "falcon",
&#47&#47     "falcon_multipart",
&#47&#47     &#47&#47 Docs
&#47&#47     "sphinx",
&#47&#47     "sphinx_rtd_theme",
&#47&#47     "flake8-html"
&#47&#47 ]

&#47&#47 required packages for testing
&#47&#47 test_requirements = [
&#47&#47     &quotpep8&quot,
&#47&#47     &quotflake8&quot,
&#47&#47     &quotpytest&quot,
&#47&#47     &quotpytest-cov&quot,
&#47&#47     &quotpytest-mock&quot,
&#47&#47     &quotpylint&quot,
&#47&#47 ]

&#47&#47 check if GPU available
</a>p = subprocess.Popen([&quotcommand -v nvidia-smi&quot], stdout=subprocess.PIPE, shell=True)
out = p.communicate()[0].decode(&quotutf8&quot)
gpu_available = len(out) &gt; 0

&#47&#47 check python version
py3_ver = int(platform.python_version().split(&quot.&quot)[1])

&#47&#47 Tensorflow version (make sure CPU/MKL/GPU versions exist before changing)
tf_version = &quot1.12.0&quot
tf_mkl_url = &quothttps://storage.googleapis.com/intel-optimized-tensorflow/tensorflow-{}-cp3{}-cp3{}m-linux_x86_64.whl&quot

&#47&#47 default TF is CPU
chosen_tf = &quottensorflow=={}&quot.format(tf_version)
&#47&#47 check system is linux for MKL/GPU backends
if &quotlinux&quot in sys.platform:
    system_type = &quotlinux&quot
    tf_be = os.getenv(&quotNLP_ARCHITECT_BE&quot, False)
    if tf_be and &quotmkl&quot == tf_be.lower():
        if py3_ver == 5 or py3_ver == 6:
            tf_mkl_url_real = tf_mkl_url.format(tf_version, py3_ver, py3_ver)
            subprocess.call([sys.executable, &quot-m&quot, &quotpip&quot, &quotinstall&quot, tf_mkl_url_real])
    elif tf_be and &quotgpu&quot == tf_be.lower() and gpu_available:
        chosen_tf = &quottensorflow-gpu=={}&quot.format(tf_version)

<a id="change">for r in install_requirements:
    if r.startswith(&quottensorflow==&quot):
        install_requirements[install_requirements.index(r)] = chosen_tf

</a>with open(&quotREADME.md&quot, encoding=&quotutf8&quot) as fp:
    long_desc = fp.read()

with io.open(os.path.join(root, &quotnlp_architect&quot, &quotversion.py&quot), encoding=&quotutf8&quot) as f:</code></pre>