<html><h3>700abc65fd2172a2c6809dd9b72cf50fc2407772,allennlp/models/encoder_decoders/composed_seq2seq.py,ComposedSeq2Seq,__init__,#ComposedSeq2Seq#Any#Any#Any#Any#Any#Any#Any#,48
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self._encoder = encoder
        self._decoder = decoder

        <a id="change">if self._encoder.get_output_dim() != self._decoder.get_output_dim():
            raise ConfigurationError(
                f"Encoder output dimension {self._encoder.get_output_dim()} should be"
                f" equal to decoder dimension {self._decoder.get_output_dim()}."
            )
       </a> if tied_source_embedder_key:
            &#47&#47 A bit of a ugly hack to tie embeddings.
            &#47&#47 Works only for `BasicTextFieldEmbedder`, and since
            &#47&#47 it can have multiple embedders, and `SeqDecoder` contains only a single embedder, we need
            &#47&#47 the key to select the source embedder to replace it with the target embedder from the decoder.
            if not isinstance(self._source_text_embedder, BasicTextFieldEmbedder):
                raise ConfigurationError(
                    "Unable to tie embeddings,"
                    "Source text embedder is not an instance of `BasicTextFieldEmbedder`."
                )

            source_embedder = self._source_text_embedder._token_embedders[tied_source_embedder_key]
            if not isinstance(source_embedder, Embedding):
                raise ConfigurationError(
                    "Unable to tie embeddings,"
                    "Selected source embedder is not an instance of `Embedding`."
                )
            <a id="change">if source_embedder.get_output_dim() != self._decoder.target_embedder.get_output_dim():
                raise ConfigurationError(
                    f"Output Dimensions mismatch between" f"source embedder and target embedder."
                )
           </a> <a id="change">self._source_text_embedder._token_embedders[
                tied_source_embedder_key
            ] = self._decoder.target_embedder</a>
        initializer(self)

    @overrides
    def forward(</code></pre><h3>After Change</h3><pre><code class='java'>
        encoder: Seq2SeqEncoder,
        decoder: SeqDecoder,
        tied_source_embedder_key: Optional[str] = None,
        initializer: InitializerApplicator = InitializerApplicator()<a id="change">,
        **kwargs,
    ) -&gt; None:

        super().__init__(vocab, **kwargs)

        self._source_text_embedder = source_text_embedder
        self._encoder = encoder
        self._decoder = decoder

        if self._encoder.get_output_dim() != self._decoder.get_output_dim():
            raise ConfigurationError(
   </a>             f"Encoder output dimension {self._encoder.get_output_dim()} should be"
                f" equal to decoder dimension {self._decoder.get_output_dim()}."
            )
        if tied_source_embedder_key:</code></pre><img src="24275840.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 10</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/allenai/allennlp/commit/700abc65fd2172a2c6809dd9b72cf50fc2407772#diff-72ee7e31870989d3f338643934daa891065889ef15d85ff22ee1e91db8472f5dL40' target='_blank'>Link</a></div><div id='project'> Project Name: allenai/allennlp</div><div id='commit'> Commit Name: 700abc65fd2172a2c6809dd9b72cf50fc2407772</div><div id='time'> Time: 2020-02-03</div><div id='author'> Author: mattg@allenai.org</div><div id='file'> File Name: allennlp/models/encoder_decoders/composed_seq2seq.py</div><div id='class'> Class Name: ComposedSeq2Seq</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/keras-team/autokeras/commit/13aa31bc1a0b87d6c4b5e787c9b041ec83831c34#diff-f607e6a0b58cd1d7cbef1451d1b0a93b4ffe437b096fc35e385930902845a520L110' target='_blank'>Link</a></div><div id='project'> Project Name: keras-team/autokeras</div><div id='commit'> Commit Name: 13aa31bc1a0b87d6c4b5e787c9b041ec83831c34</div><div id='time'> Time: 2020-07-31</div><div id='author'> Author: jin@tamu.edu</div><div id='file'> File Name: autokeras/blocks/reduction.py</div><div id='class'> Class Name: SpatialReduction</div><div id='method'> Method Name: build</div><BR><BR><div id='link'><a href='https://github.com/microsoft/nni/commit/aa51e79cdbcbedbedeef68bcef646b2d43993753#diff-2eea3f0598af286c399565f109f3ac5157139a5a12f09039ec6c3561db96d699L492' target='_blank'>Link</a></div><div id='project'> Project Name: microsoft/nni</div><div id='commit'> Commit Name: aa51e79cdbcbedbedeef68bcef646b2d43993753</div><div id='time'> Time: 2019-11-25</div><div id='author'> Author: Quanlu.Zhang@microsoft.com</div><div id='file'> File Name: src/sdk/pynni/nni/ppo_tuner/ppo_tuner.py</div><div id='class'> Class Name: PPOTuner</div><div id='method'> Method Name: _actions_to_config</div><BR>